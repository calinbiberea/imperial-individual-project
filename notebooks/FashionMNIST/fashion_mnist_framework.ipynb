{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9a2214e-4e45-460b-88c9-0b53bf2a8a77",
   "metadata": {},
   "source": [
    "# FashionMNIST: Framework"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05846bb8-d6aa-4c30-9f03-011ebcac1635",
   "metadata": {},
   "source": [
    "## Imports and FashionMNIST loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e0185ec-5c51-4234-b79f-e471152f1f08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook will use PyTorch Device: CUDA\n",
      "Notebook will use PyTorch Device: CUDA\n",
      "Notebook will use PyTorch Device: CUDA\n",
      "Notebook will use PyTorch Device: CUDA\n"
     ]
    }
   ],
   "source": [
    "# Imports all the module paths\n",
    "import sys\n",
    "\n",
    "import torch\n",
    "\n",
    "sys.path.append(\"../../\")\n",
    "\n",
    "# Loads the rest of the modules\n",
    "\n",
    "# File containing all the required training methods\n",
    "import defences.fashion_mnist as defences\n",
    "\n",
    "# For testing\n",
    "import utils.clean_test as clean_test\n",
    "\n",
    "# Contains the data loadders\n",
    "import utils.dataloaders as dataloaders\n",
    "\n",
    "# For printing outcomes\n",
    "# import utils.printing as printing\n",
    "\n",
    "# Example printing, but I removed it to simplify results\n",
    "# for epsilon in epsilons:\n",
    "#     printing.print_attack(\n",
    "#         model,\n",
    "#         testSetLoader,\n",
    "#         \"FGSM\",\n",
    "#         attacks[\"FGSM\"],\n",
    "#         epsilon=epsilon,\n",
    "#     )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d57efed4-18e9-4f06-9bf2-56f375cf4150",
   "metadata": {},
   "source": [
    "## Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1399fca3-c63d-418e-9a7c-9dd4ca45cb29",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_ROOT = \"../../datasets/\"\n",
    "\n",
    "trainSetLoader, _, testSetLoader = dataloaders.get_Fashion_MNIST_data_loaders(\n",
    "    DATA_ROOT,\n",
    "    trainSetSize=50000,\n",
    "    validationSetSize=0,\n",
    "    batchSize=128,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58ef2487-bc3a-4d62-8b04-0d2adec1df86",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Save path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5adb40d-bea1-482d-aa07-7bd44da7f9e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_LOAD_ROOT = \"../../models_data/FashionMNIST/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20b3024c-60b1-409d-97d6-558eda065dd2",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Load the Attacks For Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58da1290-0174-4fca-be31-11f540c37b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A possible attacks array (for nice printing):\n",
    "# Some attacks use a helper library\n",
    "import torchattacks\n",
    "\n",
    "import attacks.fgsm as fgsm\n",
    "import attacks.ifgsm as ifgsm\n",
    "import attacks.pgd as pgd\n",
    "import utils.attacking as attacking\n",
    "\n",
    "attacks = {}\n",
    "\n",
    "attacks[\"FGSM\"] = fgsm.fgsm_attack\n",
    "attacks[\"I-FGSM\"] = ifgsm.ifgsm_attack\n",
    "attacks[\"PGD\"] = pgd.pgd_attack"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b4088b2-fe46-4f2b-8564-688cfd54b365",
   "metadata": {},
   "source": [
    "## PGD + $CW_{2}$ Dual Adversarial Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab054fdd-e942-4070-a6b2-82b65634ba79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7f9fcd609eb41f4bae3cc63594bd95a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adversarial Training Progress:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e74ccc4eb884e6ea5809dbc71e3286f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e443109c0a84b0186d1b12b03dfc520",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c66af239d1c044c2884991e803cc553a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77dae0b648194bb7b3636657c6481f24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c62deb2ec9244508d4430341bc43029",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2395e7c4fcf4869ae91bda8f015b4b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca01ff29889e4f0dbaa449c7fb51f44a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cae92a28eed4313a2fd91efe405bb6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "307c68c7913d4c6ba487dd3fae89732d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a1081ca339f443f9c2e0157c2ef1e39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c6b42eb218343dfa4ec1427e62a17d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ddbb47513854591b55b8fc0bc7db3fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea69029a3c0e42918afb700b8289a51f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbddcf772dbc492284c1282237771c53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdab174bf56b4d9ea902f80c5a440722",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa1c1b65bdee4302ac8991113844c826",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8585ec8f3e3445d69f7915a227c6c1d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "adb637f80346450aa0a27267c45975ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22d4f5dae22e4e029e70ba74af5bf5fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc22de65e5f245499e476256b0bcfc68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... done!\n"
     ]
    }
   ],
   "source": [
    "# Weak epsilon 0.15, normal 0.35, strong 0.65\n",
    "framework_model = defences.dual_adversarial_training(\n",
    "    trainSetLoader,\n",
    "    attack_function1=attacks[\"PGD\"],\n",
    "    attack_function2=None,\n",
    "    load_if_available=True,\n",
    "    load_path=SAVE_LOAD_ROOT + \"/fashion_mnist_framework\",\n",
    "    epsilon=0.25,\n",
    "    alpha=(2 / 255),\n",
    "    iterations=7,\n",
    "    steps=500,\n",
    "    c=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4dbc5f8c-ae2f-4775-8846-2b9b3663fb97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing the model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing Progress:   0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... done! Accuracy: 88.22%\n"
     ]
    }
   ],
   "source": [
    "clean_test.test_trained_model(framework_model, testSetLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b11bd61-eb19-4f29-b284-ddff0857f8ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "torch.save(framework_model, SAVE_LOAD_ROOT + \"/fashion_mnist_framework\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "29cf6898-5f65-4d3b-a26c-d8f3b507d9c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Several values to use for the epsilons\n",
    "epsilons = [0, 0.05, 0.1, 0.2, 0.35, 0.55, 0.75, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3c3bc29d-8432-4363-91c8-307f77aa874a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing the model under FGSM Attack using epsilon = 0, alpha = None...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FGSM Attack Testing Progress:   0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... done! Accuracy: 88.22%\n",
      "\n",
      "\n",
      "Testing the model under FGSM Attack using epsilon = 0.05, alpha = None...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FGSM Attack Testing Progress:   0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... done! Accuracy: 78.79%\n",
      "\n",
      "\n",
      "Testing the model under FGSM Attack using epsilon = 0.1, alpha = None...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FGSM Attack Testing Progress:   0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... done! Accuracy: 67.85%\n",
      "\n",
      "\n",
      "Testing the model under FGSM Attack using epsilon = 0.2, alpha = None...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FGSM Attack Testing Progress:   0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... done! Accuracy: 42.01%\n",
      "\n",
      "\n",
      "Testing the model under FGSM Attack using epsilon = 0.35, alpha = None...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FGSM Attack Testing Progress:   0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... done! Accuracy: 8.08%\n",
      "\n",
      "\n",
      "Testing the model under FGSM Attack using epsilon = 0.55, alpha = None...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FGSM Attack Testing Progress:   0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... done! Accuracy: 3.76%\n",
      "\n",
      "\n",
      "Testing the model under FGSM Attack using epsilon = 0.75, alpha = None...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FGSM Attack Testing Progress:   0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... done! Accuracy: 5.77%\n",
      "\n",
      "\n",
      "Testing the model under FGSM Attack using epsilon = 1, alpha = None...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FGSM Attack Testing Progress:   0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... done! Accuracy: 7.69%\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Run test for each epsilon\n",
    "for epsilon in epsilons:\n",
    "    attacking.attack_model(\n",
    "        framework_model,\n",
    "        testSetLoader,\n",
    "        \"FGSM\",\n",
    "        attacks[\"FGSM\"],\n",
    "        epsilon=epsilon,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ccc2b2df-4076-4282-a6d0-2f0e30248741",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Several values to use for the epsilons\n",
    "epsilons = [0, 4 / 255, 0.05, 0.1, 0.2, 0.35, 0.55, 0.75, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7caae95d-1f85-433c-a6b2-7fb279cc77cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing the model under PGD Attack using epsilon = 0, alpha = 0.00784313725490196...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD Attack Testing Progress:   0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... done! Accuracy: 88.22%\n",
      "\n",
      "\n",
      "Testing the model under PGD Attack using epsilon = 0.01568627450980392, alpha = 0.00784313725490196...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD Attack Testing Progress:   0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... done! Accuracy: 85.44%\n",
      "\n",
      "\n",
      "Testing the model under PGD Attack using epsilon = 0.05, alpha = 0.00784313725490196...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD Attack Testing Progress:   0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... done! Accuracy: 79.85%\n",
      "\n",
      "\n",
      "Testing the model under PGD Attack using epsilon = 0.1, alpha = 0.00784313725490196...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD Attack Testing Progress:   0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... done! Accuracy: 77.34%\n",
      "\n",
      "\n",
      "Testing the model under PGD Attack using epsilon = 0.2, alpha = 0.00784313725490196...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD Attack Testing Progress:   0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... done! Accuracy: 75.4%\n",
      "\n",
      "\n",
      "Testing the model under PGD Attack using epsilon = 0.35, alpha = 0.00784313725490196...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD Attack Testing Progress:   0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... done! Accuracy: 71.25%\n",
      "\n",
      "\n",
      "Testing the model under PGD Attack using epsilon = 0.55, alpha = 0.00784313725490196...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD Attack Testing Progress:   0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... done! Accuracy: 53.12%\n",
      "\n",
      "\n",
      "Testing the model under PGD Attack using epsilon = 0.75, alpha = 0.00784313725490196...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD Attack Testing Progress:   0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... done! Accuracy: 28.69%\n",
      "\n",
      "\n",
      "Testing the model under PGD Attack using epsilon = 1, alpha = 0.00784313725490196...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD Attack Testing Progress:   0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... done! Accuracy: 7.66%\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epsilon in epsilons:\n",
    "    attacking.attack_model(\n",
    "        framework_model,\n",
    "        testSetLoader,\n",
    "        \"PGD\",\n",
    "        attacks[\"PGD\"],\n",
    "        epsilon=epsilon,\n",
    "        alpha=(2 / 255),\n",
    "        iterations=7,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "957ba698-3b5e-46cb-ae7d-9db7a6a74298",
   "metadata": {},
   "outputs": [],
   "source": [
    "deepfool_attack = torchattacks.DeepFool(framework_model, steps=10)\n",
    "attacks[\"DeepFool\"] = deepfool_attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b6691010-43a2-4a6d-8b69-48e0ee6b105a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing the model under DeepFool Attack...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "DeepFool Attack Testing Progress:   0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... done! Accuracy: 41.73%\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "attacking.attack_model(\n",
    "    framework_model,\n",
    "    testSetLoader,\n",
    "    \"DeepFool\",\n",
    "    attacks[\"DeepFool\"],\n",
    "    library=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "721ce949-c858-445e-a934-1f4d590c14ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "cw_attack = torchattacks.CW(framework_model, c=1, steps=500)\n",
    "attacks[\"CW\"] = cw_attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7de35609-d3b1-4f45-8901-2a05e415b1d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing the model under CW Attack...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "CW Attack Testing Progress:   0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... done! Accuracy: 71.4%\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "attacking.attack_model(\n",
    "    framework_model,\n",
    "    testSetLoader,\n",
    "    \"CW\",\n",
    "    attacks[\"CW\"],\n",
    "    library=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b6013df4-2341-4d2b-8cb1-6a1f02bc0764",
   "metadata": {},
   "outputs": [],
   "source": [
    "cw_attack = torchattacks.CW(framework_model, c=5, steps=500)\n",
    "attacks[\"CW\"] = cw_attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "65d34c86-7a5b-4c66-a918-363cdc47ea2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing the model under CW Attack...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "CW Attack Testing Progress:   0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... done! Accuracy: 11.0%\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "attacking.attack_model(\n",
    "    framework_model,\n",
    "    testSetLoader,\n",
    "    \"CW\",\n",
    "    attacks[\"CW\"],\n",
    "    library=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ebfeab1-3028-4f41-95cb-1ef6e90746f7",
   "metadata": {},
   "source": [
    "## Add PCA Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ef732644-3754-4662-9793-d76fe8eacab4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook will use PyTorch Device: CUDA\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.decomposition import PCA\n",
    "from torch.autograd import Variable\n",
    "from tqdm.notebook import tnrange, tqdm\n",
    "\n",
    "# Define the `device` PyTorch will be running on, please hope it is CUDA\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Notebook will use PyTorch Device: \" + device.upper())\n",
    "\n",
    "# Copy the MNIST data and then fit using PCA\n",
    "# First convert to numpy arrays (and make it float)\n",
    "numpyTrainingData = trainSetLoader.dataset.data.numpy().astype(\"float32\")\n",
    "# Note you also need to reshape the input data for your sanity\n",
    "reshapedNumpyTrainingData = numpyTrainingData.reshape((len(numpyTrainingData), 28 * 28))\n",
    "\n",
    "# Then perform PCA on training data to get principal components\n",
    "# Note it should reflect dimension of image, i.e. 28 * 28\n",
    "pca = PCA(n_components=28 * 28).fit(reshapedNumpyTrainingData)\n",
    "\n",
    "# For testing\n",
    "loss_function = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1e5772a-0d24-4924-900a-1af53e359107",
   "metadata": {},
   "source": [
    "#### With clean images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "16d323f4-bce0-41d3-b566-ac2f1952ba24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37\n"
     ]
    }
   ],
   "source": [
    "# Now on clean data check if there are any adversarial samples\n",
    "numpyTestData = testSetLoader.dataset.data.numpy().astype(\"float32\")\n",
    "reshapedNumpyTestData = numpyTestData.reshape((len(numpyTestData), 28 * 28))\n",
    "\n",
    "# Original predictions on data\n",
    "testTensor = torch.from_numpy(\n",
    "    np.reshape(numpyTestData, (len(numpyTestData), 1, 28, 28))\n",
    ").to(device)\n",
    "logits = framework_model(testTensor).detach().cpu().numpy()\n",
    "predictions_base = np.array([np.argmax(logits[i]) for i in range(len(numpyTestData))])\n",
    "\n",
    "# Transform clean data along principal components\n",
    "transformedTestData = pca.transform(reshapedNumpyTestData)\n",
    "\n",
    "# Decides how many of the least significant coefficients (of components) to perturb\n",
    "num_components = 200\n",
    "\n",
    "# How many trials to run\n",
    "num_trials = 25\n",
    "\n",
    "# Track results\n",
    "result = np.zeros(len(numpyTestData), dtype=int)\n",
    "\n",
    "# Actual attempts\n",
    "for trial in range(num_trials):\n",
    "    random_noise = np.random.standard_normal(size=num_components)\n",
    "\n",
    "    # Copy the data\n",
    "    transformedTestDataNoisy = np.copy(transformedTestData)\n",
    "\n",
    "    # Update the components with the right data\n",
    "    for index in range(len(numpyTestData)):\n",
    "        transformedTestDataNoisy[index][(28 * 28 - num_components) :] += (\n",
    "            10 * random_noise\n",
    "        )\n",
    "\n",
    "    # Now calculate the inverse using PCA and the noise\n",
    "    inverseTestDataNoisy = pca.inverse_transform(transformedTestDataNoisy)\n",
    "\n",
    "    # Reshape into image\n",
    "    testDataNoisy = np.reshape(inverseTestDataNoisy, (len(numpyTestData), 1, 28, 28))\n",
    "\n",
    "    # Predict\n",
    "    testTensor = torch.from_numpy(\n",
    "        np.reshape(testDataNoisy, (len(testDataNoisy), 1, 28, 28))\n",
    "    ).to(device)\n",
    "    logits = framework_model(testTensor).detach().cpu().numpy()\n",
    "    predictions_modified = np.array(\n",
    "        [np.argmax(logits[i]) for i in range(len(testDataNoisy))]\n",
    "    )\n",
    "\n",
    "    check = np.not_equal(predictions_modified, predictions_base)\n",
    "    result = np.logical_or(check, result)\n",
    "\n",
    "# Printing\n",
    "print(np.sum(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61cdf305-6e2e-4d52-861d-8f4e57b6f47f",
   "metadata": {},
   "source": [
    "#### With FGSM images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d816f0bf-6b54-48b2-9592-02092222ff15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing Progress:   0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3714\n"
     ]
    }
   ],
   "source": [
    "# Now do the same on adversarial data check if there are any adversarial samples\n",
    "# Use a pretty progress bar to show updates\n",
    "data = []\n",
    "\n",
    "for j, (images, labels) in enumerate(\n",
    "    tqdm(testSetLoader, desc=\"Testing Progress\", leave=False)\n",
    "):\n",
    "    # Cast to proper tensor\n",
    "    images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "    # Perturb the images using the attack\n",
    "    perturbed_images = fgsm.fgsm_attack(\n",
    "        images,\n",
    "        labels,\n",
    "        framework_model,\n",
    "        loss_function,\n",
    "        epsilon=0.75,\n",
    "        alpha=None,\n",
    "        scale=True,\n",
    "        iterations=None,\n",
    "    )\n",
    "\n",
    "    for perturbed_image in perturbed_images:\n",
    "        data.append(perturbed_image.detach().cpu().numpy())\n",
    "\n",
    "data = np.asarray(data)\n",
    "numpyTestData = data.astype(\"float32\")\n",
    "reshapedNumpyTestData = numpyTestData.reshape((len(numpyTestData), 28 * 28))\n",
    "\n",
    "# Original predictions on data\n",
    "testTensor = torch.from_numpy(\n",
    "    np.reshape(numpyTestData, (len(numpyTestData), 1, 28, 28))\n",
    ").to(device)\n",
    "logits = framework_model(testTensor).detach().cpu().numpy()\n",
    "predictions_base = np.array([np.argmax(logits[i]) for i in range(len(numpyTestData))])\n",
    "\n",
    "# Transform clean data along principal components\n",
    "transformedTestData = pca.transform(reshapedNumpyTestData)\n",
    "\n",
    "# Decides how many of the least significant coefficients (of components) to perturb\n",
    "num_components = 200\n",
    "\n",
    "# How many trials to run\n",
    "num_trials = 25\n",
    "\n",
    "# Track results\n",
    "result = np.zeros(len(numpyTestData), dtype=int)\n",
    "\n",
    "# Actual attempts\n",
    "for trial in range(num_trials):\n",
    "    random_noise = np.random.standard_normal(size=num_components)\n",
    "\n",
    "    # Copy the data\n",
    "    transformedTestDataNoisy = np.copy(transformedTestData)\n",
    "\n",
    "    # Update the components with the right data\n",
    "    for index in range(len(numpyTestData)):\n",
    "        transformedTestDataNoisy[index][(28 * 28 - num_components) :] += (\n",
    "            10 * random_noise\n",
    "        )\n",
    "\n",
    "    # Now calculate the inverse using PCA and the noise\n",
    "    inverseTestDataNoisy = pca.inverse_transform(transformedTestDataNoisy)\n",
    "\n",
    "    # Reshape into image\n",
    "    testDataNoisy = np.reshape(inverseTestDataNoisy, (len(numpyTestData), 1, 28, 28))\n",
    "\n",
    "    # Predict\n",
    "    testTensor = torch.from_numpy(\n",
    "        np.reshape(testDataNoisy, (len(testDataNoisy), 1, 28, 28))\n",
    "    ).to(device)\n",
    "    logits = logits = framework_model(testTensor).detach().cpu().numpy()\n",
    "    predictions_modified = np.array(\n",
    "        [np.argmax(logits[i]) for i in range(len(testDataNoisy))]\n",
    "    )\n",
    "\n",
    "    check = np.not_equal(predictions_modified, predictions_base)\n",
    "    result = np.logical_or(check, result)\n",
    "\n",
    "# Printing\n",
    "print(np.sum(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "007a2692-430f-407e-bde9-7096a5765c81",
   "metadata": {},
   "source": [
    "#### With PGD images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "11eb2534-23ab-4b90-a271-736f4da183fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing Progress:   0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9412\n"
     ]
    }
   ],
   "source": [
    "# Now do the same on adversarial data check if there are any adversarial samples\n",
    "# Use a pretty progress bar to show updates\n",
    "data = []\n",
    "\n",
    "for j, (images, labels) in enumerate(\n",
    "    tqdm(testSetLoader, desc=\"Testing Progress\", leave=False)\n",
    "):\n",
    "    # Cast to proper tensor\n",
    "    images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "    # Perturb the images using the attack\n",
    "    perturbed_images = pgd.pgd_attack(\n",
    "        images,\n",
    "        labels,\n",
    "        framework_model,\n",
    "        loss_function,\n",
    "        epsilon=0.0001,\n",
    "        alpha=(2 / 255),\n",
    "        iterations=20,\n",
    "        scale=True,\n",
    "    )\n",
    "\n",
    "    for perturbed_image in perturbed_images:\n",
    "        data.append(perturbed_image.detach().cpu().numpy())\n",
    "\n",
    "data = np.asarray(data)\n",
    "numpyTestData = data.astype(\"float32\")\n",
    "reshapedNumpyTestData = numpyTestData.reshape((len(numpyTestData), 28 * 28))\n",
    "\n",
    "# Original predictions on data\n",
    "testTensor = torch.from_numpy(\n",
    "    np.reshape(numpyTestData, (len(numpyTestData), 1, 28, 28))\n",
    ").to(device)\n",
    "logits = framework_model(testTensor).detach().cpu().numpy()\n",
    "predictions_base = np.array([np.argmax(logits[i]) for i in range(len(numpyTestData))])\n",
    "\n",
    "# Transform clean data along principal components\n",
    "transformedTestData = pca.transform(reshapedNumpyTestData)\n",
    "\n",
    "# Decides how many of the least significant coefficients (of components) to perturb\n",
    "num_components = 200\n",
    "\n",
    "# How many trials to run\n",
    "num_trials = 25\n",
    "\n",
    "# Track results\n",
    "result = np.zeros(len(numpyTestData), dtype=int)\n",
    "\n",
    "# Actual attempts\n",
    "for trial in range(num_trials):\n",
    "    random_noise = np.random.standard_normal(size=num_components)\n",
    "\n",
    "    # Copy the data\n",
    "    transformedTestDataNoisy = np.copy(transformedTestData)\n",
    "\n",
    "    # Update the components with the right data\n",
    "    for index in range(len(numpyTestData)):\n",
    "        transformedTestDataNoisy[index][(28 * 28 - num_components) :] += (\n",
    "            10 * random_noise\n",
    "        )\n",
    "\n",
    "    # Now calculate the inverse using PCA and the noise\n",
    "    inverseTestDataNoisy = pca.inverse_transform(transformedTestDataNoisy)\n",
    "\n",
    "    # Reshape into image\n",
    "    testDataNoisy = np.reshape(inverseTestDataNoisy, (len(numpyTestData), 1, 28, 28))\n",
    "\n",
    "    # Predict\n",
    "    testTensor = torch.from_numpy(\n",
    "        np.reshape(testDataNoisy, (len(testDataNoisy), 1, 28, 28))\n",
    "    ).to(device)\n",
    "    logits = logits = framework_model(testTensor).detach().cpu().numpy()\n",
    "    predictions_modified = np.array(\n",
    "        [np.argmax(logits[i]) for i in range(len(testDataNoisy))]\n",
    "    )\n",
    "\n",
    "    check = np.not_equal(predictions_modified, predictions_base)\n",
    "    result = np.logical_or(check, result)\n",
    "\n",
    "# Printing\n",
    "print(np.sum(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ae74eef3-1a70-4c53-aa1e-c8774546fb7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing Progress:   0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9163\n"
     ]
    }
   ],
   "source": [
    "# Now do the same on adversarial data check if there are any adversarial samples\n",
    "# Use a pretty progress bar to show updates\n",
    "data = []\n",
    "\n",
    "for j, (images, labels) in enumerate(\n",
    "    tqdm(testSetLoader, desc=\"Testing Progress\", leave=False)\n",
    "):\n",
    "    # Cast to proper tensor\n",
    "    images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "    # Perturb the images using the attack\n",
    "    perturbed_images = pgd.pgd_attack(\n",
    "        images,\n",
    "        labels,\n",
    "        framework_model,\n",
    "        loss_function,\n",
    "        epsilon=0.01,\n",
    "        alpha=(2 / 255),\n",
    "        iterations=200,\n",
    "        scale=True,\n",
    "    )\n",
    "\n",
    "    for perturbed_image in perturbed_images:\n",
    "        data.append(perturbed_image.detach().cpu().numpy())\n",
    "\n",
    "data = np.asarray(data)\n",
    "numpyTestData = data.astype(\"float32\")\n",
    "reshapedNumpyTestData = numpyTestData.reshape((len(numpyTestData), 28 * 28))\n",
    "\n",
    "# Original predictions on data\n",
    "testTensor = torch.from_numpy(\n",
    "    np.reshape(numpyTestData, (len(numpyTestData), 1, 28, 28))\n",
    ").to(device)\n",
    "logits = framework_model(testTensor).detach().cpu().numpy()\n",
    "predictions_base = np.array([np.argmax(logits[i]) for i in range(len(numpyTestData))])\n",
    "\n",
    "# Transform clean data along principal components\n",
    "transformedTestData = pca.transform(reshapedNumpyTestData)\n",
    "\n",
    "# Decides how many of the least significant coefficients (of components) to perturb\n",
    "num_components = 200\n",
    "\n",
    "# How many trials to run\n",
    "num_trials = 25\n",
    "\n",
    "# Track results\n",
    "result = np.zeros(len(numpyTestData), dtype=int)\n",
    "\n",
    "# Actual attempts\n",
    "for trial in range(num_trials):\n",
    "    random_noise = np.random.standard_normal(size=num_components)\n",
    "\n",
    "    # Copy the data\n",
    "    transformedTestDataNoisy = np.copy(transformedTestData)\n",
    "\n",
    "    # Update the components with the right data\n",
    "    for index in range(len(numpyTestData)):\n",
    "        transformedTestDataNoisy[index][(28 * 28 - num_components) :] += (\n",
    "            10 * random_noise\n",
    "        )\n",
    "\n",
    "    # Now calculate the inverse using PCA and the noise\n",
    "    inverseTestDataNoisy = pca.inverse_transform(transformedTestDataNoisy)\n",
    "\n",
    "    # Reshape into image\n",
    "    testDataNoisy = np.reshape(inverseTestDataNoisy, (len(numpyTestData), 1, 28, 28))\n",
    "\n",
    "    # Predict\n",
    "    testTensor = torch.from_numpy(\n",
    "        np.reshape(testDataNoisy, (len(testDataNoisy), 1, 28, 28))\n",
    "    ).to(device)\n",
    "    logits = logits = framework_model(testTensor).detach().cpu().numpy()\n",
    "    predictions_modified = np.array(\n",
    "        [np.argmax(logits[i]) for i in range(len(testDataNoisy))]\n",
    "    )\n",
    "\n",
    "    check = np.not_equal(predictions_modified, predictions_base)\n",
    "    result = np.logical_or(check, result)\n",
    "\n",
    "# Printing\n",
    "print(np.sum(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c54932b0-ef86-44fd-aaa7-430cd8322e4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing Progress:   0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3141\n"
     ]
    }
   ],
   "source": [
    "# Now do the same on adversarial data check if there are any adversarial samples\n",
    "# Use a pretty progress bar to show updates\n",
    "data = []\n",
    "\n",
    "for j, (images, labels) in enumerate(\n",
    "    tqdm(testSetLoader, desc=\"Testing Progress\", leave=False)\n",
    "):\n",
    "    # Cast to proper tensor\n",
    "    images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "    # Perturb the images using the attack\n",
    "    perturbed_images = pgd.pgd_attack(\n",
    "        images,\n",
    "        labels,\n",
    "        framework_model,\n",
    "        loss_function,\n",
    "        epsilon=0.85,\n",
    "        alpha=(2 / 255),\n",
    "        iterations=200,\n",
    "        scale=True,\n",
    "    )\n",
    "\n",
    "    for perturbed_image in perturbed_images:\n",
    "        data.append(perturbed_image.detach().cpu().numpy())\n",
    "\n",
    "data = np.asarray(data)\n",
    "numpyTestData = data.astype(\"float32\")\n",
    "reshapedNumpyTestData = numpyTestData.reshape((len(numpyTestData), 28 * 28))\n",
    "\n",
    "# Original predictions on data\n",
    "testTensor = torch.from_numpy(\n",
    "    np.reshape(numpyTestData, (len(numpyTestData), 1, 28, 28))\n",
    ").to(device)\n",
    "logits = framework_model(testTensor).detach().cpu().numpy()\n",
    "predictions_base = np.array([np.argmax(logits[i]) for i in range(len(numpyTestData))])\n",
    "\n",
    "# Transform clean data along principal components\n",
    "transformedTestData = pca.transform(reshapedNumpyTestData)\n",
    "\n",
    "# Decides how many of the least significant coefficients (of components) to perturb\n",
    "num_components = 300\n",
    "\n",
    "# How many trials to run\n",
    "num_trials = 25\n",
    "\n",
    "# Track results\n",
    "result = np.zeros(len(numpyTestData), dtype=int)\n",
    "\n",
    "# Actual attempts\n",
    "for trial in range(num_trials):\n",
    "    random_noise = np.random.standard_normal(size=num_components)\n",
    "\n",
    "    # Copy the data\n",
    "    transformedTestDataNoisy = np.copy(transformedTestData)\n",
    "\n",
    "    # Update the components with the right data\n",
    "    for index in range(len(numpyTestData)):\n",
    "        transformedTestDataNoisy[index][(28 * 28 - num_components) :] += (\n",
    "            10 * random_noise\n",
    "        )\n",
    "\n",
    "    # Now calculate the inverse using PCA and the noise\n",
    "    inverseTestDataNoisy = pca.inverse_transform(transformedTestDataNoisy)\n",
    "\n",
    "    # Reshape into image\n",
    "    testDataNoisy = np.reshape(inverseTestDataNoisy, (len(numpyTestData), 1, 28, 28))\n",
    "\n",
    "    # Predict\n",
    "    testTensor = torch.from_numpy(\n",
    "        np.reshape(testDataNoisy, (len(testDataNoisy), 1, 28, 28))\n",
    "    ).to(device)\n",
    "    logits = logits = framework_model(testTensor).detach().cpu().numpy()\n",
    "    predictions_modified = np.array(\n",
    "        [np.argmax(logits[i]) for i in range(len(testDataNoisy))]\n",
    "    )\n",
    "\n",
    "    check = np.not_equal(predictions_modified, predictions_base)\n",
    "    result = np.logical_or(check, result)\n",
    "\n",
    "# Printing\n",
    "print(np.sum(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe36db14-dbab-4bd4-991c-a77906968015",
   "metadata": {},
   "source": [
    "#### With $CW_{2}$ Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c1c46b49-7526-4f49-bd55-5228243df464",
   "metadata": {},
   "outputs": [],
   "source": [
    "cw_attack = torchattacks.CW(framework_model, c=1, steps=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "530badda-7676-46c0-9478-a151409d534d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing Progress:   0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9026\n"
     ]
    }
   ],
   "source": [
    "# Now do the same on adversarial data check if there are any adversarial samples\n",
    "# Use a pretty progress bar to show updates\n",
    "data = []\n",
    "\n",
    "for j, (images, labels) in enumerate(\n",
    "    tqdm(testSetLoader, desc=\"Testing Progress\", leave=False)\n",
    "):\n",
    "    # Cast to proper tensor\n",
    "    images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "    # Perturb the images using the attack\n",
    "    perturbed_images = cw_attack(\n",
    "        images,\n",
    "        labels,\n",
    "    )\n",
    "\n",
    "    for perturbed_image in perturbed_images:\n",
    "        data.append(perturbed_image.detach().cpu().numpy())\n",
    "\n",
    "data = np.asarray(data)\n",
    "numpyTestData = data.astype(\"float32\")\n",
    "reshapedNumpyTestData = numpyTestData.reshape((len(numpyTestData), 28 * 28))\n",
    "\n",
    "# Original predictions on data\n",
    "testTensor = torch.from_numpy(\n",
    "    np.reshape(numpyTestData, (len(numpyTestData), 1, 28, 28))\n",
    ").to(device)\n",
    "logits = framework_model(testTensor).detach().cpu().numpy()\n",
    "predictions_base = np.array([np.argmax(logits[i]) for i in range(len(numpyTestData))])\n",
    "\n",
    "# Transform clean data along principal components\n",
    "transformedTestData = pca.transform(reshapedNumpyTestData)\n",
    "\n",
    "# Decides how many of the least significant coefficients (of components) to perturb\n",
    "num_components = 200\n",
    "\n",
    "# How many trials to run\n",
    "num_trials = 25\n",
    "\n",
    "# Track results\n",
    "result = np.zeros(len(numpyTestData), dtype=int)\n",
    "\n",
    "# Actual attempts\n",
    "for trial in range(num_trials):\n",
    "    random_noise = np.random.standard_normal(size=num_components)\n",
    "\n",
    "    # Copy the data\n",
    "    transformedTestDataNoisy = np.copy(transformedTestData)\n",
    "\n",
    "    # Update the components with the right data\n",
    "    for index in range(len(numpyTestData)):\n",
    "        transformedTestDataNoisy[index][(28 * 28 - num_components) :] += (\n",
    "            10 * random_noise\n",
    "        )\n",
    "\n",
    "    # Now calculate the inverse using PCA and the noise\n",
    "    inverseTestDataNoisy = pca.inverse_transform(transformedTestDataNoisy)\n",
    "\n",
    "    # Reshape into image\n",
    "    testDataNoisy = np.reshape(inverseTestDataNoisy, (len(numpyTestData), 1, 28, 28))\n",
    "\n",
    "    # Predict\n",
    "    testTensor = torch.from_numpy(\n",
    "        np.reshape(testDataNoisy, (len(testDataNoisy), 1, 28, 28))\n",
    "    ).to(device)\n",
    "    logits = logits = framework_model(testTensor).detach().cpu().numpy()\n",
    "    predictions_modified = np.array(\n",
    "        [np.argmax(logits[i]) for i in range(len(testDataNoisy))]\n",
    "    )\n",
    "\n",
    "    check = np.not_equal(predictions_modified, predictions_base)\n",
    "    result = np.logical_or(check, result)\n",
    "\n",
    "# Printing\n",
    "print(np.sum(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ffde8b7b-02a0-465a-b615-0af7930c2c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cw_attack = torchattacks.CW(framework_model, c=3, steps=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "14baad83-4aab-4719-b884-b6a9df84be7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing Progress:   0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9545\n"
     ]
    }
   ],
   "source": [
    "# Now do the same on adversarial data check if there are any adversarial samples\n",
    "# Use a pretty progress bar to show updates\n",
    "data = []\n",
    "\n",
    "for j, (images, labels) in enumerate(\n",
    "    tqdm(testSetLoader, desc=\"Testing Progress\", leave=False)\n",
    "):\n",
    "    # Cast to proper tensor\n",
    "    images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "    # Perturb the images using the attack\n",
    "    perturbed_images = cw_attack(\n",
    "        images,\n",
    "        labels,\n",
    "    )\n",
    "\n",
    "    for perturbed_image in perturbed_images:\n",
    "        data.append(perturbed_image.detach().cpu().numpy())\n",
    "\n",
    "data = np.asarray(data)\n",
    "numpyTestData = data.astype(\"float32\")\n",
    "reshapedNumpyTestData = numpyTestData.reshape((len(numpyTestData), 28 * 28))\n",
    "\n",
    "# Original predictions on data\n",
    "testTensor = torch.from_numpy(\n",
    "    np.reshape(numpyTestData, (len(numpyTestData), 1, 28, 28))\n",
    ").to(device)\n",
    "logits = framework_model(testTensor).detach().cpu().numpy()\n",
    "predictions_base = np.array([np.argmax(logits[i]) for i in range(len(numpyTestData))])\n",
    "\n",
    "# Transform clean data along principal components\n",
    "transformedTestData = pca.transform(reshapedNumpyTestData)\n",
    "\n",
    "# Decides how many of the least significant coefficients (of components) to perturb\n",
    "num_components = 200\n",
    "\n",
    "# How many trials to run\n",
    "num_trials = 25\n",
    "\n",
    "# Track results\n",
    "result = np.zeros(len(numpyTestData), dtype=int)\n",
    "\n",
    "# Actual attempts\n",
    "for trial in range(num_trials):\n",
    "    random_noise = np.random.standard_normal(size=num_components)\n",
    "\n",
    "    # Copy the data\n",
    "    transformedTestDataNoisy = np.copy(transformedTestData)\n",
    "\n",
    "    # Update the components with the right data\n",
    "    for index in range(len(numpyTestData)):\n",
    "        transformedTestDataNoisy[index][(28 * 28 - num_components) :] += (\n",
    "            10 * random_noise\n",
    "        )\n",
    "\n",
    "    # Now calculate the inverse using PCA and the noise\n",
    "    inverseTestDataNoisy = pca.inverse_transform(transformedTestDataNoisy)\n",
    "\n",
    "    # Reshape into image\n",
    "    testDataNoisy = np.reshape(inverseTestDataNoisy, (len(numpyTestData), 1, 28, 28))\n",
    "\n",
    "    # Predict\n",
    "    testTensor = torch.from_numpy(\n",
    "        np.reshape(testDataNoisy, (len(testDataNoisy), 1, 28, 28))\n",
    "    ).to(device)\n",
    "    logits = logits = framework_model(testTensor).detach().cpu().numpy()\n",
    "    predictions_modified = np.array(\n",
    "        [np.argmax(logits[i]) for i in range(len(testDataNoisy))]\n",
    "    )\n",
    "\n",
    "    check = np.not_equal(predictions_modified, predictions_base)\n",
    "    result = np.logical_or(check, result)\n",
    "\n",
    "# Printing\n",
    "print(np.sum(result))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
