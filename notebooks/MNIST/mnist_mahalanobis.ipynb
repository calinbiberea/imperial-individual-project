{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf6b41ca-5f07-4710-baae-24a1ed8dda14",
   "metadata": {},
   "source": [
    "# MNIST: Training and Testing on a Clean Dataset & Adversarial Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "079b34ed-646a-4a6d-9804-456031bbbe7f",
   "metadata": {},
   "source": [
    "## Imports and MNIST loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc6f794-8ded-4bca-bd88-62c136ee6128",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports all the module paths\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from tqdm.notebook import tnrange, tqdm\n",
    "\n",
    "sys.path.append(\"../../\")\n",
    "\n",
    "# Loads the rest of the modules\n",
    "# File containing all the required training methods\n",
    "import defences.mnist as defences\n",
    "\n",
    "# For testing\n",
    "import utils.clean_test as clean_test\n",
    "\n",
    "# Contains the data loadders\n",
    "import utils.dataloaders as dataloaders\n",
    "\n",
    "# For printing outcomes\n",
    "# import utils.printing as printing\n",
    "\n",
    "# Example printing, but I removed it to simplify results\n",
    "# for epsilon in epsilons:\n",
    "#     printing.print_attack(\n",
    "#         model,\n",
    "#         testSetLoader,\n",
    "#         \"FGSM\",\n",
    "#         attacks[\"FGSM\"],\n",
    "#         epsilon=epsilon,\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b26f2046-3c5c-435a-a11d-bbeb41de6db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the `device` PyTorch will be running on, please hope it is CUDA\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Notebook will use PyTorch Device: \" + device.upper())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4fee513-bdec-474f-9a4b-9c7a7321b7f2",
   "metadata": {},
   "source": [
    "## Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3cf35b0-a90d-4e04-b2d8-57e52f553b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_ROOT = \"../../datasets/\"\n",
    "\n",
    "trainSetLoader, _, testSetLoader = dataloaders.get_MNIST_data_loaders(\n",
    "    DATA_ROOT,\n",
    "    trainSetSize=50000,\n",
    "    validationSetSize=0,\n",
    "    batchSize=128,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b460fcff-4216-45da-b876-a6a4ec9e8941",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Attacks and Their Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7493eab6-d768-4f30-ac44-5c80f33fbef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A possible attacks array (for nice printing):\n",
    "# Some attacks use a helper library\n",
    "import torchattacks\n",
    "\n",
    "import attacks.fgsm as fgsm\n",
    "import attacks.ifgsm as ifgsm\n",
    "import attacks.pgd as pgd\n",
    "import utils.attacking as attacking\n",
    "\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "attacks = {}\n",
    "\n",
    "attacks[\"FGSM\"] = fgsm.fgsm_attack\n",
    "attacks[\"I-FGSM\"] = ifgsm.ifgsm_attack\n",
    "attacks[\"PGD\"] = pgd.pgd_attack"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efae51ea-8cf4-4b1a-9c38-949b04e81d60",
   "metadata": {},
   "source": [
    "## Train a model (let's say standard for now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df83148d-a234-464f-90ee-e383f11349f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_LOAD_ROOT = \"../../models_data/MNIST\"\n",
    "\n",
    "standard_model = defences.standard_training(\n",
    "    trainSetLoader,\n",
    "    load_if_available=True,\n",
    "    load_path=SAVE_LOAD_ROOT + \"/mnist_standard_mahalanobis\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "006d2a5c-2df4-4da7-963f-a035d62ddf03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "clean_test.test_trained_model(standard_model, testSetLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c48235d0-c883-4e64-bb29-9deef17c259d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A possible attacks array (for nice printing):\n",
    "# Some attacks use a helper library\n",
    "import torchattacks\n",
    "\n",
    "import attacks.fgsm as fgsm\n",
    "import attacks.ifgsm as ifgsm\n",
    "import attacks.pgd as pgd\n",
    "import utils.attacking as attacking\n",
    "\n",
    "attacks = {}\n",
    "\n",
    "attacks[\"FGSM\"] = fgsm.fgsm_attack\n",
    "attacks[\"I-FGSM\"] = ifgsm.ifgsm_attack\n",
    "attacks[\"PGD\"] = pgd.pgd_attack"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3479d3c-e588-478f-8140-dbc1a682d023",
   "metadata": {},
   "source": [
    "## A Simple Unified Framework for Detecting Out-of-Distribution Samples and Adversarial Attacks\n",
    "https://arxiv.org/abs/1807.03888"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a71adfa8-0bee-48c3-9028-afe3ec7c39cf",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Step 1: extract shape of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a6a7fa-8440-444e-8849-0df42e091260",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract shape of features (useful for later)\n",
    "fake_input = torch.rand(2, 1, 28, 28).cuda()\n",
    "fake_input = Variable(fake_input)\n",
    "\n",
    "# Temporary list of features\n",
    "out_list = standard_model.feature_list(fake_input)[1]\n",
    "\n",
    "# Construct the feature list\n",
    "num_feature_layers = len(out_list)\n",
    "feature_list = np.empty(num_feature_layers)\n",
    "\n",
    "for feature_layer in range(num_feature_layers):\n",
    "    feature_list[feature_layer] = out_list[feature_layer].size(1)\n",
    "\n",
    "print(feature_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dde2049-912a-4ea7-9611-3f65a387e2e0",
   "metadata": {},
   "source": [
    "### Step 2: extract mean and covariance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "744c175d-0897-4e30-9efc-c9b56fe82ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.covariance\n",
    "\n",
    "\n",
    "# Returns the sample mean and precision (which the original code defines as inverse of covariance)\n",
    "# Also, returns per class values: list of class means, list of precisions\n",
    "def sample_estimator(trainSetLoader, model, feature_list):\n",
    "    # Number of classes\n",
    "    num_classes = 10\n",
    "\n",
    "    # Construct the covariance first\n",
    "    group_lasso = sklearn.covariance.EmpiricalCovariance(assume_centered=False)\n",
    "    correct, total = 0, 0\n",
    "\n",
    "    # Here this also applies to layer wise features\n",
    "    num_output = len(feature_list)\n",
    "    num_sample_per_class = np.empty(num_classes)\n",
    "    num_sample_per_class.fill(0)\n",
    "    list_features = []\n",
    "\n",
    "    # list_features[<layer>][<label>] is a list that holds the features\n",
    "    # in a specific layer of a specific label (class)\n",
    "    for i in range(num_output):\n",
    "        temp_list = []\n",
    "        for j in range(num_classes):\n",
    "            temp_list.append(0)\n",
    "        list_features.append(temp_list)\n",
    "\n",
    "    for j, (image, label) in enumerate(\n",
    "        tqdm(\n",
    "            trainSetLoader.dataset,\n",
    "            desc=\"Going through the images one by one\",\n",
    "            leave=False,\n",
    "        )\n",
    "    ):\n",
    "        # Make tensor\n",
    "        image = np.reshape(image, (1, 1, 28, 28))\n",
    "        image = image.to(device)\n",
    "\n",
    "        # This is for extracting the feature list\n",
    "        output, out_features = model.feature_list(image)\n",
    "\n",
    "        # Get hidden features\n",
    "        for index in range(num_output):\n",
    "            out_features[index] = out_features[index].view(\n",
    "                out_features[index].size(0), out_features[index].size(1), -1\n",
    "            )\n",
    "            out_features[index] = torch.mean(out_features[index].data, 2)\n",
    "\n",
    "        # Compute the accuracy\n",
    "        pred = output.data.max(1)[1]\n",
    "        equal_flag = pred.eq(torch.tensor(label).to(device)).cpu()\n",
    "        correct += equal_flag.sum()\n",
    "\n",
    "        # Construct the sample matrix (this is layer by layer)\n",
    "        if num_sample_per_class[label] == 0:\n",
    "            out_count = 0\n",
    "            for out in out_features:\n",
    "                list_features[out_count][label] = out[0].view(1, -1)\n",
    "                out_count += 1\n",
    "        else:\n",
    "            out_count = 0\n",
    "            for out in out_features:\n",
    "                list_features[out_count][label] = torch.cat(\n",
    "                    (list_features[out_count][label], out[0].view(1, -1)), 0\n",
    "                )\n",
    "                out_count += 1\n",
    "        num_sample_per_class[label] += 1\n",
    "\n",
    "    sample_class_mean = []\n",
    "    out_count = 0\n",
    "    for num_feature in feature_list:\n",
    "        temp_list = torch.Tensor(num_classes, int(num_feature)).to(device)\n",
    "        for j in range(num_classes):\n",
    "            temp_list[j] = torch.mean(list_features[out_count][j], 0)\n",
    "        sample_class_mean.append(temp_list)\n",
    "        out_count += 1\n",
    "\n",
    "    precision = []\n",
    "    for k in range(num_output):\n",
    "        X = 0\n",
    "        for i in range(num_classes):\n",
    "            if i == 0:\n",
    "                X = list_features[k][i] - sample_class_mean[k][i]\n",
    "            else:\n",
    "                X = torch.cat((X, list_features[k][i] - sample_class_mean[k][i]), 0)\n",
    "\n",
    "        # Find inverse\n",
    "        group_lasso.fit(X.cpu().numpy())\n",
    "        temp_precision = group_lasso.precision_\n",
    "        temp_precision = torch.from_numpy(temp_precision).float().cuda()\n",
    "        precision.append(temp_precision)\n",
    "\n",
    "    # This is just a print from the code, which helps me understand\n",
    "    # what they were actually doing\n",
    "    print(\n",
    "        \"\\n Training Accuracy:({:.2f}%)\\n\".format(\n",
    "            100.0 * correct / len(trainSetLoader.dataset)\n",
    "        )\n",
    "    )\n",
    "\n",
    "    return sample_class_mean, precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7bdcef1-90de-4f8c-be75-91c12175272a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_mean, precision = sample_estimator(\n",
    "    testSetLoader, standard_model, feature_list=feature_list\n",
    ")\n",
    "\n",
    "# Looks very ugly, I don't recommend printing this\n",
    "# print(sample_mean, precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d180c4-ccd3-41e5-9895-631982a777a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the proposed (in the paper) Mahalanobis confidence score on (adversarial)\n",
    "# samples at a specific layer index with set magnitude\n",
    "def mahalanobis_score(\n",
    "    trainSetLoader,\n",
    "    model,\n",
    "    sample_mean,\n",
    "    precision,\n",
    "    layer_index,\n",
    "    magnitude,\n",
    "):\n",
    "    num_classes = 10\n",
    "    mahalanobis = []\n",
    "\n",
    "    # Do it one by one so I do not go fully insane and cry\n",
    "    for j, (image, label) in enumerate(\n",
    "        tqdm(\n",
    "            trainSetLoader.dataset,\n",
    "            desc=\"Going through the images one by one\",\n",
    "            leave=False,\n",
    "        )\n",
    "    ):\n",
    "        # Make tensor\n",
    "        image = np.reshape(image, (1, 1, 28, 28))\n",
    "        image = image.to(device)\n",
    "        image.requires_grad = True\n",
    "        # image.retain_grad()\n",
    "\n",
    "        label = torch.tensor(label).to(device)\n",
    "\n",
    "        # Extract features\n",
    "        out_features = model.intermediate_forward(image, layer_index)\n",
    "        out_features = out_features.view(out_features.size(0), out_features.size(1), -1)\n",
    "        out_features = torch.mean(out_features, 2)\n",
    "\n",
    "        gaussian_score = 0\n",
    "        for i in range(num_classes):\n",
    "            batch_sample_mean = sample_mean[layer_index][i]\n",
    "            zero_f = out_features.data - batch_sample_mean\n",
    "            term_gau = (\n",
    "                -0.5\n",
    "                * torch.mm(torch.mm(zero_f, precision[layer_index]), zero_f.t()).diag()\n",
    "            )\n",
    "            if i == 0:\n",
    "                gaussian_score = term_gau.view(-1, 1)\n",
    "            else:\n",
    "                gaussian_score = torch.cat((gaussian_score, term_gau.view(-1, 1)), 1)\n",
    "\n",
    "        # Input_processing\n",
    "        sample_pred = gaussian_score.max(1)[1]\n",
    "        batch_sample_mean = sample_mean[layer_index].index_select(0, sample_pred)\n",
    "        zero_f = out_features - Variable(batch_sample_mean)\n",
    "        pure_gau = (\n",
    "            -0.5\n",
    "            * torch.mm(\n",
    "                torch.mm(zero_f, Variable(precision[layer_index])), zero_f.t()\n",
    "            ).diag()\n",
    "        )\n",
    "        loss = torch.mean(-pure_gau)\n",
    "        loss.backward()\n",
    "\n",
    "        gradient = torch.ge(image.grad.data, 0)\n",
    "        gradient = (gradient.float() - 0.5) * 2\n",
    "        gradient.index_copy_(\n",
    "            1,\n",
    "            torch.LongTensor([0]).cuda(),\n",
    "            gradient.index_select(1, torch.LongTensor([0]).cuda()) / (0.2023),\n",
    "        )\n",
    "        gradient.index_copy_(\n",
    "            1,\n",
    "            torch.LongTensor([1]).cuda(),\n",
    "            gradient.index_select(1, torch.LongTensor([1]).cuda()) / (0.1994),\n",
    "        )\n",
    "        gradient.index_copy_(\n",
    "            1,\n",
    "            torch.LongTensor([2]).cuda(),\n",
    "            gradient.index_select(1, torch.LongTensor([2]).cuda()) / (0.2010),\n",
    "        )\n",
    "        tempInputs = torch.add(data.data, -magnitude, gradient)\n",
    "\n",
    "\n",
    "#     for data_index in range(int(np.floor(test_data.size(0) / batch_size))):\n",
    "#         target = test_label[total : total + batch_size].cuda()\n",
    "#         data = test_data[total : total + batch_size].cuda()\n",
    "#         total += batch_size\n",
    "#         data, target = Variable(data, requires_grad=True), Variable(target)\n",
    "\n",
    "\n",
    "#         noise_out_features = model.intermediate_forward(\n",
    "#             Variable(tempInputs, volatile=True), layer_index\n",
    "#         )\n",
    "#         noise_out_features = noise_out_features.view(\n",
    "#             noise_out_features.size(0), noise_out_features.size(1), -1\n",
    "#         )\n",
    "#         noise_out_features = torch.mean(noise_out_features, 2)\n",
    "#         noise_gaussian_score = 0\n",
    "#         for i in range(num_classes):\n",
    "#             batch_sample_mean = sample_mean[layer_index][i]\n",
    "#             zero_f = noise_out_features.data - batch_sample_mean\n",
    "#             term_gau = (\n",
    "#                 -0.5\n",
    "#                 * torch.mm(torch.mm(zero_f, precision[layer_index]), zero_f.t()).diag()\n",
    "#             )\n",
    "#             if i == 0:\n",
    "#                 noise_gaussian_score = term_gau.view(-1, 1)\n",
    "#             else:\n",
    "#                 noise_gaussian_score = torch.cat(\n",
    "#                     (noise_gaussian_score, term_gau.view(-1, 1)), 1\n",
    "#                 )\n",
    "\n",
    "#         noise_gaussian_score, _ = torch.max(noise_gaussian_score, dim=1)\n",
    "#         Mahalanobis.extend(noise_gaussian_score.cpu().numpy())\n",
    "\n",
    "#     return Mahalanobis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac27cce-4d9d-4a82-999e-8ca1f323c9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In here you finally compute the Mahalanobis score and hope for the best\n",
    "# magnitude_list = [0.0, 0.01, 0.005, 0.002, 0.0014, 0.001, 0.0005]\n",
    "magnitude_list = [0.0]\n",
    "for magnitude in magnitude_list:\n",
    "    print(\"Mahalanobis score with the following magnitude: {}\".format(magnitude))\n",
    "\n",
    "    # First do the score on clean data\n",
    "    for feature_num in range(num_feature_layers):\n",
    "        mahalanobis_in_temp = mahalanobis_score(\n",
    "            testSetLoader,\n",
    "            standard_model,\n",
    "            sample_mean,\n",
    "            precision,\n",
    "            feature_num,\n",
    "            magnitude,\n",
    "        )\n",
    "        mahalanobis_in_temp = np.asarray(mahalanobis_in_temp, dtype=np.float32)\n",
    "        if feature_num == 0:\n",
    "            mahalanobis_in = mahalanobis_in_temp.reshape(\n",
    "                (mahalanobis_in_temp.shape[0], -1)\n",
    "            )\n",
    "        else:\n",
    "            mahalanobis_in = np.concatenate(\n",
    "                (\n",
    "                    mahalanobis_in_temp,\n",
    "                    mahalanobis_in_temp.reshape((mahalanobis_in_temp.shape[0], -1)),\n",
    "                ),\n",
    "                axis=1,\n",
    "            )\n",
    "\n",
    "    # Then do the score on adversarial data\n",
    "#     for i in range(num_output):\n",
    "#         M_out = get_Mahalanobis_score_adv(\n",
    "#             model,\n",
    "#             test_adv_data,\n",
    "#             test_label,\n",
    "#             args.num_classes,\n",
    "#             args.outf,\n",
    "#             args.net_type,\n",
    "#             sample_mean,\n",
    "#             precision,\n",
    "#             i,\n",
    "#             magnitude,\n",
    "#         )\n",
    "#         M_out = np.asarray(M_out, dtype=np.float32)\n",
    "#         if i == 0:\n",
    "#             Mahalanobis_out = M_out.reshape((M_out.shape[0], -1))\n",
    "#         else:\n",
    "#             Mahalanobis_out = np.concatenate(\n",
    "#                 (Mahalanobis_out, M_out.reshape((M_out.shape[0], -1))), axis=1\n",
    "#             )\n",
    "\n",
    "#     # Then do the score on noisy data\n",
    "#     for i in range(num_output):\n",
    "#         M_noisy = lib_generation.get_Mahalanobis_score_adv(\n",
    "#             model,\n",
    "#             test_noisy_data,\n",
    "#             test_label,\n",
    "#             args.num_classes,\n",
    "#             args.outf,\n",
    "#             args.net_type,\n",
    "#             sample_mean,\n",
    "#             precision,\n",
    "#             i,\n",
    "#             magnitude,\n",
    "#         )\n",
    "#         M_noisy = np.asarray(M_noisy, dtype=np.float32)\n",
    "#         if i == 0:\n",
    "#             Mahalanobis_noisy = M_noisy.reshape((M_noisy.shape[0], -1))\n",
    "#         else:\n",
    "#             Mahalanobis_noisy = np.concatenate(\n",
    "#                 (Mahalanobis_noisy, M_noisy.reshape((M_noisy.shape[0], -1))), axis=1\n",
    "#             )\n",
    "\n",
    "#     Mahalanobis_in = np.asarray(Mahalanobis_in, dtype=np.float32)\n",
    "#     Mahalanobis_out = np.asarray(Mahalanobis_out, dtype=np.float32)\n",
    "#     Mahalanobis_noisy = np.asarray(Mahalanobis_noisy, dtype=np.float32)\n",
    "#     Mahalanobis_pos = np.concatenate((Mahalanobis_in, Mahalanobis_noisy))\n",
    "\n",
    "#     Mahalanobis_data, Mahalanobis_labels = lib_generation.merge_and_generate_labels(\n",
    "#         Mahalanobis_out, Mahalanobis_pos\n",
    "#     )\n",
    "#     file_name = os.path.join(\n",
    "#         args.outf,\n",
    "#         \"Mahalanobis_%s_%s_%s.npy\" % (str(magnitude), args.dataset, args.adv_type),\n",
    "#     )\n",
    "\n",
    "#     Mahalanobis_data = np.concatenate((Mahalanobis_data, Mahalanobis_labels), axis=1)\n",
    "#     np.save(file_name, Mahalanobis_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eebb13e-9224-4d77-8ec7-b26144cbb317",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
