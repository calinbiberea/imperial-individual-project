{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf6b41ca-5f07-4710-baae-24a1ed8dda14",
   "metadata": {},
   "source": [
    "# MNIST: Training and Testing on a Clean Dataset & Adversarial Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "079b34ed-646a-4a6d-9804-456031bbbe7f",
   "metadata": {},
   "source": [
    "## Imports and MNIST loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "adc6f794-8ded-4bca-bd88-62c136ee6128",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook will use PyTorch Device: CUDA\n",
      "Notebook will use PyTorch Device: CUDA\n",
      "Notebook will use PyTorch Device: CUDA\n",
      "Notebook will use PyTorch Device: CUDA\n"
     ]
    }
   ],
   "source": [
    "# Imports all the module paths\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from tqdm.notebook import tnrange, tqdm\n",
    "\n",
    "sys.path.append(\"../../\")\n",
    "\n",
    "# Loads the rest of the modules\n",
    "\n",
    "# File containing all the required training methods\n",
    "import defences.mnist as defences\n",
    "\n",
    "# For testing\n",
    "import utils.clean_test as clean_test\n",
    "\n",
    "# Contains the data loadders\n",
    "import utils.dataloaders as dataloaders\n",
    "\n",
    "# For printing outcomes\n",
    "# import utils.printing as printing\n",
    "\n",
    "# Example printing, but I removed it to simplify results\n",
    "# for epsilon in epsilons:\n",
    "#     printing.print_attack(\n",
    "#         model,\n",
    "#         testSetLoader,\n",
    "#         \"FGSM\",\n",
    "#         attacks[\"FGSM\"],\n",
    "#         epsilon=epsilon,\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b26f2046-3c5c-435a-a11d-bbeb41de6db6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook will use PyTorch Device: CUDA\n"
     ]
    }
   ],
   "source": [
    "# Define the `device` PyTorch will be running on, please hope it is CUDA\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Notebook will use PyTorch Device: \" + device.upper())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4fee513-bdec-474f-9a4b-9c7a7321b7f2",
   "metadata": {},
   "source": [
    "## Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3cf35b0-a90d-4e04-b2d8-57e52f553b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_ROOT = \"../../datasets/\"\n",
    "\n",
    "trainSetLoader, _, testSetLoader = dataloaders.get_MNIST_data_loaders(\n",
    "    DATA_ROOT,\n",
    "    trainSetSize=50000,\n",
    "    validationSetSize=0,\n",
    "    batchSize=128,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b460fcff-4216-45da-b876-a6a4ec9e8941",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Attacks and Their Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7493eab6-d768-4f30-ac44-5c80f33fbef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A possible attacks array (for nice printing):\n",
    "# Some attacks use a helper library\n",
    "import torchattacks\n",
    "\n",
    "import attacks.fgsm as fgsm\n",
    "import attacks.ifgsm as ifgsm\n",
    "import attacks.pgd as pgd\n",
    "import utils.attacking as attacking\n",
    "\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "attacks = {}\n",
    "\n",
    "attacks[\"FGSM\"] = fgsm.fgsm_attack\n",
    "attacks[\"I-FGSM\"] = ifgsm.ifgsm_attack\n",
    "attacks[\"PGD\"] = pgd.pgd_attack"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efae51ea-8cf4-4b1a-9c38-949b04e81d60",
   "metadata": {},
   "source": [
    "## Load two models (standard and FGSM trained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "df83148d-a234-464f-90ee-e383f11349f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LeNet5(\n",
       "  (conv1): Conv2d(1, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "  (max_pool_1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "  (max_pool_2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (fc1): Linear(in_features=3136, out_features=1024, bias=True)\n",
       "  (fc2): Linear(in_features=1024, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "standard_model = torch.load(\"../../models_data/MNIST/mnist_standard\")\n",
    "standard_model.eval()\n",
    "\n",
    "pgd_model = torch.load(\"../../models_data/MNIST/mnist_pgd\")\n",
    "pgd_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "006d2a5c-2df4-4da7-963f-a035d62ddf03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing the model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing Progress:   0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... done! Accuracy: 99.14%\n",
      "Testing the model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing Progress:   0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... done! Accuracy: 99.27%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the two models\n",
    "clean_test.test_trained_model(standard_model, testSetLoader)\n",
    "clean_test.test_trained_model(pgd_model, testSetLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ce3d9a8d-5792-4d0d-8eec-43bb657b0761",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found already trained model...\n",
      "... loaded!\n"
     ]
    }
   ],
   "source": [
    "SAVE_LOAD_ROOT = \"../../models_data/MNIST\"\n",
    "\n",
    "model = defences.standard_training(\n",
    "    trainSetLoader,\n",
    "    load_if_available=True,\n",
    "    load_path=SAVE_LOAD_ROOT + \"/mnist_standard_with_feature_list\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "61f6411d-741f-4823-a737-bf74667695a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing the model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing Progress:   0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... done! Accuracy: 99.23%\n"
     ]
    }
   ],
   "source": [
    "# Test the model\n",
    "clean_test.test_trained_model(model, testSetLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d3d14986-d539-4337-ab84-ea7b88747d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "torch.save(model, SAVE_LOAD_ROOT + \"/mnist_standard_with_feature_list\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c48235d0-c883-4e64-bb29-9deef17c259d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A possible attacks array (for nice printing):\n",
    "# Some attacks use a helper library\n",
    "import torchattacks\n",
    "\n",
    "import attacks.fgsm as fgsm\n",
    "import attacks.ifgsm as ifgsm\n",
    "import attacks.pgd as pgd\n",
    "import utils.attacking as attacking\n",
    "\n",
    "attacks = {}\n",
    "\n",
    "attacks[\"FGSM\"] = fgsm.fgsm_attack\n",
    "attacks[\"I-FGSM\"] = ifgsm.ifgsm_attack\n",
    "attacks[\"PGD\"] = pgd.pgd_attack"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc582167-ff7d-4693-b8e8-8e9c6acec531",
   "metadata": {},
   "source": [
    "## Classification score approach for detecting adversarial example in deep neural network\n",
    "https://link.springer.com/article/10.1007/s11042-020-09167-z"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6acc1f2c-cbdc-428c-b694-12fa7dae2c77",
   "metadata": {},
   "source": [
    "## Standard Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4c84132e-c96e-4244-905e-b2821500c2b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing Progress:   0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... done! Rejected 1, Accepted 9999, Accuracy: 99.14991499149914%\n"
     ]
    }
   ],
   "source": [
    "# Here you decide on the threshold for the clean dataset\n",
    "threshold = 0.1\n",
    "\n",
    "# Rejected\n",
    "accepted = 0\n",
    "rejected = 0\n",
    "correct = 0\n",
    "\n",
    "# Use a pretty progress bar to show updates\n",
    "for j, (images, labels) in enumerate(\n",
    "    tqdm(testSetLoader, desc=\"Testing Progress\", leave=False)\n",
    "):\n",
    "    # Cast to proper tensor\n",
    "    images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "    # Predict\n",
    "    logits = standard_model(images)\n",
    "\n",
    "    # The highest class represents the chosen class (input, k, dimension)\n",
    "    _, preds = torch.topk(logits, 2, 1)\n",
    "\n",
    "    # Check each image and see if it is adversarial\n",
    "    for index in range(len(images)):\n",
    "        max_index = preds[index][0]\n",
    "        sec_index = preds[index][1]\n",
    "\n",
    "        diff = logits[index][max_index] - logits[index][sec_index]\n",
    "\n",
    "        if diff < threshold:\n",
    "            rejected += 1\n",
    "        else:\n",
    "            accepted += 1\n",
    "            correct += max_index == labels[index]\n",
    "\n",
    "\n",
    "print(\n",
    "    \"... done! Rejected {}, Accepted {}, Accuracy: {}%\".format(\n",
    "        rejected, accepted, float(correct) * 100 / accepted\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "765a66e2-7bab-488a-a68d-14a1e4e9a46b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing Progress:   0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... done! Rejected 791, Accepted 9209, Accuracy: 4.104680204148116%\n"
     ]
    }
   ],
   "source": [
    "# Here you decide on the threshold for the clean dataset\n",
    "threshold = 0.4\n",
    "\n",
    "# Rejected\n",
    "accepted = 0\n",
    "rejected = 0\n",
    "correct = 0\n",
    "\n",
    "# Use a pretty progress bar to show updates\n",
    "for j, (images, labels) in enumerate(\n",
    "    tqdm(testSetLoader, desc=\"Testing Progress\", leave=False)\n",
    "):\n",
    "    # Cast to proper tensor\n",
    "    images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "    # Perturb the images using the attack\n",
    "    perturbed_images = fgsm.fgsm_attack(\n",
    "        images,\n",
    "        labels,\n",
    "        standard_model,\n",
    "        loss_function,\n",
    "        epsilon=0.35,\n",
    "        alpha=None,\n",
    "        scale=True,\n",
    "        iterations=None,\n",
    "    )\n",
    "\n",
    "    # Predict\n",
    "    logits = standard_model(perturbed_images)\n",
    "\n",
    "    # The highest class represents the chosen class (input, k, dimension)\n",
    "    _, preds = torch.topk(logits, 2, 1)\n",
    "\n",
    "    # Check each image and see if it is adversarial\n",
    "    for index in range(len(images)):\n",
    "        max_index = preds[index][0]\n",
    "        sec_index = preds[index][1]\n",
    "\n",
    "        diff = logits[index][max_index] - logits[index][sec_index]\n",
    "\n",
    "        if diff < threshold:\n",
    "            rejected += 1\n",
    "        else:\n",
    "            accepted += 1\n",
    "            correct += max_index == labels[index]\n",
    "\n",
    "print(\n",
    "    \"... done! Rejected {}, Accepted {}, Accuracy: {}%\".format(\n",
    "        rejected, accepted, float(correct) * 100 / accepted\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45d6601d-214d-4c83-8bcf-135c595b8c86",
   "metadata": {},
   "source": [
    "## PGD Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5e0858f2-f772-4e25-b4c1-233dfda4d50a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing Progress:   0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... done! Rejected 6, Accepted 9994, Accuracy: 99.28957374424655%\n"
     ]
    }
   ],
   "source": [
    "# Here you decide on the threshold for the clean dataset\n",
    "threshold = 0.1\n",
    "\n",
    "# Rejected\n",
    "accepted = 0\n",
    "rejected = 0\n",
    "correct = 0\n",
    "\n",
    "# Use a pretty progress bar to show updates\n",
    "for j, (images, labels) in enumerate(\n",
    "    tqdm(testSetLoader, desc=\"Testing Progress\", leave=False)\n",
    "):\n",
    "    # Cast to proper tensor\n",
    "    images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "    # Predict\n",
    "    logits = pgd_model(images)\n",
    "\n",
    "    # The highest class represents the chosen class (input, k, dimension)\n",
    "    _, preds = torch.topk(logits, 2, 1)\n",
    "\n",
    "    # Check each image and see if it is adversarial\n",
    "    for index in range(len(images)):\n",
    "        max_index = preds[index][0]\n",
    "        sec_index = preds[index][1]\n",
    "\n",
    "        diff = logits[index][max_index] - logits[index][sec_index]\n",
    "\n",
    "        if diff < threshold:\n",
    "            rejected += 1\n",
    "        else:\n",
    "            accepted += 1\n",
    "            correct += max_index == labels[index]\n",
    "\n",
    "print(\n",
    "    \"... done! Rejected {}, Accepted {}, Accuracy: {}%\".format(\n",
    "        rejected, accepted, float(correct) * 100 / accepted\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "905ad550-203c-4487-9f73-a7ace56f077a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing Progress:   0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... done! Rejected 822, Accepted 9178, Accuracy: 29.58160819350621%\n"
     ]
    }
   ],
   "source": [
    "# Here you decide on the threshold for the clean dataset\n",
    "threshold = 0.25\n",
    "\n",
    "# Rejected\n",
    "accepted = 0\n",
    "rejected = 0\n",
    "correct = 0\n",
    "\n",
    "# Use a pretty progress bar to show updates\n",
    "for j, (images, labels) in enumerate(\n",
    "    tqdm(testSetLoader, desc=\"Testing Progress\", leave=False)\n",
    "):\n",
    "    # Cast to proper tensor\n",
    "    images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "    # Perturb the images using the attack\n",
    "    perturbed_images = fgsm.fgsm_attack(\n",
    "        images,\n",
    "        labels,\n",
    "        standard_model,\n",
    "        loss_function,\n",
    "        epsilon=0.35,\n",
    "        alpha=None,\n",
    "        scale=True,\n",
    "        iterations=None,\n",
    "    )\n",
    "\n",
    "    # Predict\n",
    "    logits = pgd_model(perturbed_images)\n",
    "\n",
    "    # The highest class represents the chosen class (input, k, dimension)\n",
    "    _, preds = torch.topk(logits, 2, 1)\n",
    "\n",
    "    # Check each image and see if it is adversarial\n",
    "    for index in range(len(images)):\n",
    "        max_index = preds[index][0]\n",
    "        sec_index = preds[index][1]\n",
    "\n",
    "        diff = logits[index][max_index] - logits[index][sec_index]\n",
    "\n",
    "        if diff < threshold:\n",
    "            rejected += 1\n",
    "        else:\n",
    "            accepted += 1\n",
    "            correct += max_index == labels[index]\n",
    "\n",
    "print(\n",
    "    \"... done! Rejected {}, Accepted {}, Accuracy: {}%\".format(\n",
    "        rejected, accepted, float(correct) * 100 / accepted\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67132d83-f70e-4113-be50-94a2f4d30dd0",
   "metadata": {},
   "source": [
    "## Maximum Mean Discrepancy Test is Aware of Adversarial Attacks\n",
    "https://arxiv.org/abs/2010.11415"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cd755c44-ae3e-4d54-9814-a9e12e540a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not implemented due to breaking changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "38503123-2a09-4f39-87db-4f23d3b1a016",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Firstly extract semantic features from trained model\n",
    "# Note: we just need the penultimate layer (so not complete pain)\n",
    "# Train a model that also returns penultimate layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3479d3c-e588-478f-8140-dbc1a682d023",
   "metadata": {},
   "source": [
    "## A Simple Unified Framework for Detecting Out-of-Distribution Samples and Adversarial Attacks\n",
    "https://arxiv.org/abs/1807.03888"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d2901bc-7664-4824-b1bc-c32b75bba168",
   "metadata": {},
   "source": [
    "## Characterizing Adversarial Subspaces Using Local Intrinsic Dimensionality\n",
    "https://arxiv.org/abs/1801.02613"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0241d618-4284-4d56-9717-17c803aa506c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect natural images\n",
    "Ind_tr = np.random.choice(len(data_all), N1, replace=False)\n",
    "Ind_te = np.delete(Ind_all, Ind_tr)\n",
    "train_data = []\n",
    "for i in Ind_tr:\n",
    "train_data.append([data_all[i], label_all[i]])\n",
    "\n",
    "dataloader = torch.utils.data.DataLoader(\n",
    "train_data,\n",
    "batch_size=opt.batch_size,\n",
    "shuffle=True,\n",
    ")\n",
    "\n",
    "# Collect adv images\n",
    "np.random.seed(seed=819 * (kk + 9) + N1)\n",
    "Ind_tr_v4 = np.random.choice(len(data_trans), N1, replace=False)\n",
    "Ind_te_v4 = np.delete(Ind_v4_all, Ind_tr_v4)\n",
    "New_CIFAR_tr = data_trans[Ind_tr_v4]\n",
    "New_CIFAR_te = data_trans[Ind_te_v4]\n",
    "\n",
    "# Initialize optimizers\n",
    "# Fetch training data\n",
    "s1 = data_all[Ind_tr]\n",
    "s2 = data_trans[Ind_tr_v4]\n",
    "S = torch.cat([s1.cpu(), s2.cpu()], 0).cuda()\n",
    "Sv = S.view(2 * N1, -1)\n",
    "\n",
    "s1 = data_org[Ind_tr]\n",
    "s2 = data_trans_org[Ind_tr_v4]\n",
    "S = torch.cat([s1.cpu(), s2.cpu()], 0).cuda()\n",
    "S_FEA = S.view(2 * N1, -1)\n",
    "\n",
    "# Train SAMMD\n",
    "\n",
    "np.random.seed(seed=1102)\n",
    "torch.manual_seed(1102)\n",
    "torch.cuda.manual_seed(1102)\n",
    "Dxy = Pdist2(Sv[:N1, :], Sv[N1:, :])\n",
    "Dxy_org = Pdist2(S_FEA[:N1, :], S_FEA[N1:, :])\n",
    "epsilonOPT = torch.log(MatConvert(np.random.rand(1) * 10 ** (-10), device, dtype))\n",
    "epsilonOPT.requires_grad = True\n",
    "sigma0 = Dxy.median()\n",
    "sigma0.requires_grad = True\n",
    "sigmaOPT = MatConvert(np.ones(1) * np.sqrt(2 * 32 * 32), device, dtype)\n",
    "sigmaOPT.requires_grad = True\n",
    "\n",
    "\n",
    "optimizer_sigma0 = torch.optim.Adam([sigma0]+[sigmaOPT]+[epsilonOPT], lr=0.0002)\n",
    "for t in range(opt.n_epochs):\n",
    "ep = torch.exp(epsilonOPT) / (1 + torch.exp(epsilonOPT))\n",
    "sigma = sigmaOPT ** 2\n",
    "TEMPa = MMDu(Sv, N1, S_FEA, sigma, sigma0, ep, is_smooth=True)\n",
    "mmd_value_tempa = -1 * (TEMPa[0] + 10 ** (-8))\n",
    "mmd_std_tempa = torch.sqrt(TEMPa[1] + 10 ** (-8))\n",
    "STAT_adaptive = torch.div(mmd_value_tempa, mmd_std_tempa)\n",
    "optimizer_sigma0.zero_grad()\n",
    "STAT_adaptive.backward(retain_graph=True)\n",
    "optimizer_sigma0.step()\n",
    "if t % 100 == 0:\n",
    "    print(\"mmd: \", -1 * mmd_value_tempa.item(), \"mmd_std: \", mmd_std_tempa.item(), \"Statistic: \",\n",
    "          -1 * STAT_adaptive.item())\n",
    "Tensor = torch.cuda.FloatTensor if cuda else torch.FloatTensor\n",
    "\n",
    "# Compute test power of MMD-D and baselines\n",
    "\n",
    "H_adaptive = np.zeros(N)\n",
    "T_adaptive = np.zeros(N)\n",
    "M_adaptive = np.zeros(N)\n",
    "\n",
    "np.random.seed(1102)\n",
    "count_adp = 0\n",
    "\n",
    "for k in range(N):\n",
    "# Fetch test data\n",
    "np.random.seed(seed=1102 * (k + 1) + N1)\n",
    "data_all_te = data_all[Ind_te]\n",
    "N_te = len(data_trans)-N1\n",
    "Ind_N_te = np.random.choice(len(Ind_te), N_te, replace=False)#9900\n",
    "s1 = data_all_te[Ind_N_te]\n",
    "s2 = data_trans[Ind_te_v4]\n",
    "S = torch.cat([s1.cpu(), s2.cpu()], 0).cuda()\n",
    "Sv = S.view(2 * N_te, -1)\n",
    "\n",
    "data_all_te = data_org[Ind_te]\n",
    "s1 = data_all_te[Ind_N_te]\n",
    "s2 = data_trans_org[Ind_te_v4]\n",
    "S = torch.cat([s1.cpu(), s2.cpu()], 0).cuda()\n",
    "S_FEA = S.view(2 * N_te, -1)\n",
    "\n",
    "h_adaptive, threshold_adaptive, mmd_value_adaptive = SAMMD_WB(Sv, N_per, N_te, S_FEA, sigma, sigma0, ep, alpha, device, dtype)\n",
    "\n",
    "# Gather results\n",
    "\n",
    "count_adp = count_adp + h_adaptive\n",
    "\n",
    "print(\"SAMMD:\", count_adp)\n",
    "\n",
    "H_adaptive[k] = h_adaptive\n",
    "T_adaptive[k] = threshold_adaptive\n",
    "M_adaptive[k] = mmd_value_adaptive"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
